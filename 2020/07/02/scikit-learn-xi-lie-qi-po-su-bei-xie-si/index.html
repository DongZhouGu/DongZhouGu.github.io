<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>scikit-learn系列七：朴素贝叶斯 | 欢迎来到，TWOTO 的博客</title><meta name="keywords" content="机器学习"><meta name="author" content="DongZhou"><meta name="copyright" content="DongZhou"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="项目地址传送门，欢迎 star 和 fork ！1. 朴素贝叶斯概述贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。朴素贝叶斯（Naive Bayers）算法是一种基于概率统计的分类方法。它在条件独立假设的基础上，使用贝叶斯定理构建算法，在文本处理领域有广泛的应用。 2. 贝叶斯理论 &amp; 条件概率2.1 贝叶斯理论我们现在有一个数据集，它由两类数据组成，数">
<meta property="og:type" content="article">
<meta property="og:title" content="scikit-learn系列七：朴素贝叶斯">
<meta property="og:url" content="https://dongzhougu.github.io/2020/07/02/scikit-learn-xi-lie-qi-po-su-bei-xie-si/index.html">
<meta property="og:site_name" content="欢迎来到，TWOTO 的博客">
<meta property="og:description" content="项目地址传送门，欢迎 star 和 fork ！1. 朴素贝叶斯概述贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。朴素贝叶斯（Naive Bayers）算法是一种基于概率统计的分类方法。它在条件独立假设的基础上，使用贝叶斯定理构建算法，在文本处理领域有广泛的应用。 2. 贝叶斯理论 &amp; 条件概率2.1 贝叶斯理论我们现在有一个数据集，它由两类数据组成，数">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2020-07-02T07:57:44.000Z">
<meta property="article:modified_time" content="2021-11-07T15:49:39.092Z">
<meta property="article:author" content="DongZhou">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://dongzhougu.github.io/2020/07/02/scikit-learn-xi-lie-qi-po-su-bei-xie-si/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'scikit-learn系列七：朴素贝叶斯',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-11-07 23:49:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: #FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }
    
    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }
    
   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}
    
    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}
    
   
    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: #49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: #2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },1000); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
 </script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="欢迎来到，TWOTO 的博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
 <div id="loading-container">
     <p class="loading-text">玩命加载中 . . . </p> 
     <div class="loading-image">
         <div></div>
         <div></div>
         <div></div>
         <div></div> 
         <div></div>
     </div>
 </div><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">29</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">欢迎来到，TWOTO 的博客</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">scikit-learn系列七：朴素贝叶斯</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-07-02T07:57:44.000Z" title="发表于 2020-07-02 15:57:44">2020-07-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-11-07T15:49:39.092Z" title="更新于 2021-11-07 23:49:39">2021-11-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="scikit-learn系列七：朴素贝叶斯"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="项目地址传送门，欢迎-star-和-fork-！"><a href="#项目地址传送门，欢迎-star-和-fork-！" class="headerlink" title="项目地址传送门，欢迎 star 和 fork ！"></a>项目地址<a target="_blank" rel="noopener" href="https://github.com/DongZhouGu/scikit-learn-ml">传送门</a>，欢迎 star 和 fork ！</h2><h2 id="1-朴素贝叶斯概述"><a href="#1-朴素贝叶斯概述" class="headerlink" title="1. 朴素贝叶斯概述"></a>1. 朴素贝叶斯概述</h2><p>贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。朴素贝叶斯（Naive Bayers）算法是一种基于概率统计的分类方法。它在条件独立假设的基础上，使用贝叶斯定理构建算法，在文本处理领域有广泛的应用。</p>
<h2 id="2-贝叶斯理论-amp-条件概率"><a href="#2-贝叶斯理论-amp-条件概率" class="headerlink" title="2. 贝叶斯理论 &amp; 条件概率"></a>2. 贝叶斯理论 &amp; 条件概率</h2><h3 id="2-1-贝叶斯理论"><a href="#2-1-贝叶斯理论" class="headerlink" title="2.1 贝叶斯理论"></a>2.1 贝叶斯理论</h3><p>我们现在有一个数据集，它由两类数据组成，数据分布如下图所示: </p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A4%BA%E4%BE%8B%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83.png" alt="朴素贝叶斯示例数据分布" title="参数已知的概率分布"></p>
<p>我们现在用 p1(x,y) 表示数据点 (x,y) 属于类别 1（图中用圆点表示的类别）的概率，用 p2(x,y) 表示数据点 (x,y) 属于类别 2（图中三角形表示的类别）的概率，那么对于一个新数据点 (x,y)，可以用下面的规则来判断它的类别: </p>
<ul>
<li>如果 p1(x,y) &gt; p2(x,y) ，那么类别为1</li>
<li>如果 p2(x,y) &gt; p1(x,y) ，那么类别为2</li>
</ul>
<p>也就是说，我们会选择高概率对应的类别。这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策。</p>
<h3 id="2-2-条件概率"><a href="#2-2-条件概率" class="headerlink" title="2.2 条件概率"></a>2.2 条件概率</h3><p>如果你对 p(x,y|c1) 符号很熟悉，那么可以跳过本小节。</p>
<p>有一个装了 7 块石头的罐子，其中 3 块是白色的，4 块是黑色的。如果从罐子中随机取出一块石头，那么是白色石头的可能性是多少？由于取石头有 7 种可能，其中 3 种为白色，所以取出白色石头的概率为 3/7 。那么取到黑色石头的概率又是多少呢？很显然，是 4/7 。我们使用 P(white) 来表示取到白色石头的概率，其概率值可以通过白色石头数目除以总的石头数目来得到。</p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/NB_2.png" alt="包含 7 块石头的集合"></p>
<p>如果这 7 块石头如下图所示，放在两个桶中，那么上述概率应该如何计算？</p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/NB_5.png" alt="7块石头放入两个桶中"></p>
<p>计算 P(white) 或者 P(black) ，如果事先我们知道石头所在桶的信息是会改变结果的。这就是所谓的条件概率（conditional probablity）。假定计算的是从 B 桶取到白色石头的概率，这个概率可以记作 P(white|bucketB) ，我们称之为“在已知石头出自 B 桶的条件下，取出白色石头的概率”。很容易得到，P(white|bucketA) 值为 2/4 ，P(white|bucketB) 的值为 1/3 。</p>
<p>条件概率的计算公式如下: </p>
<p>P(white|bucketB) = P(white and bucketB) / P(bucketB)</p>
<p>首先，我们用 B 桶中白色石头的个数除以两个桶中总的石头数，得到 P(white and bucketB) = 1/7 .其次，由于 B 桶中有 3 块石头，而总石头数为 7 ，于是 P(bucketB) 就等于 3/7 。于是又 P(white|bucketB) = P(white and bucketB) / P(bucketB) = (1/7) / (3/7) = 1/3 。</p>
<p>另外一种有效计算条件概率的方法称为贝叶斯准则。贝叶斯准则告诉我们如何交换条件概率中的条件与结果，即如果已知 P(x|c)，要求 P(c|x)，那么可以使用下面的计算方法: </p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/NB_3.png" alt="计算p(c|x)的方法"></p>
<h3 id="2-3-使用条件概率来分类"><a href="#2-3-使用条件概率来分类" class="headerlink" title="2.3 使用条件概率来分类"></a>2.3 使用条件概率来分类</h3><p>上面我们提到贝叶斯决策理论要求计算两个概率 p1(x, y) 和 p2(x, y):</p>
<ul>
<li>如果 p1(x, y) &gt; p2(x, y), 那么属于类别 1;</li>
<li>如果 p2(x, y) &gt; p1(X, y), 那么属于类别 2.</li>
</ul>
<p>这并不是贝叶斯决策理论的所有内容。使用 p1() 和 p2() 只是为了尽可能简化描述，而真正需要计算和比较的是 p(c1|x, y) 和 p(c2|x, y) .这些符号所代表的具体意义是: 给定某个由 x、y 表示的数据点，那么该数据点来自类别 c1 的概率是多少？数据点来自类别 c2 的概率又是多少？注意这些概率与概率 p(x, y|c1) 并不一样，不过可以使用贝叶斯准则来交换概率中条件与结果。具体地，应用贝叶斯准则得到: </p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/NB_4.png" alt="应用贝叶斯准则"></p>
<p>使用上面这些定义，可以定义贝叶斯分类准则为:</p>
<ul>
<li>如果 P(c1|x, y) &gt; P(c2|x, y), 那么属于类别 c1;</li>
<li>如果 P(c2|x, y) &gt; P(c1|x, y), 那么属于类别 c2.</li>
</ul>
<p>在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。我们可以观察文档中出现的词，并把每个词作为一个特征，而每个词的出现或者不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多。</p>
<p>我们假设特征之间  <strong>相互独立</strong> 。所谓 <b>独立(independence)</b> 指的是统计意义上的独立，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系，比如说，“我们”中的“我”和“们”出现的概率与这两个字相邻没有任何关系。这个假设正是朴素贝叶斯分类器中 朴素(naive) 一词的含义。朴素贝叶斯分类器中的另一个假设是，<b>每个特征同等重要</b>。</p>
<blockquote>
<p><b>Note:</b> 朴素贝叶斯分类器通常有两种实现方式: 一种基于伯努利模型实现，一种基于多项式模型实现。前者中并不考虑词在文档中出现的次数，只考虑出不出现，因此在这个意义上相当于假设词是等权重的。</p>
</blockquote>
<h2 id="3-一个简单的例子"><a href="#3-一个简单的例子" class="headerlink" title="3. 一个简单的例子"></a>3. 一个简单的例子</h2><p>我们先通过一个简单的例子，来看怎样应用朴素贝叶斯分类算法。假设有以下关于驾龄、平均车速和性别的统计数据：</p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/17634123-28f863c2b8a241e7.png" alt="img"></p>
<blockquote>
<p>现在观察到一个驾龄为2年的人，平均车速为80。问：这个人的性别是什么？</p>
</blockquote>
<p>假设 $C_{0}$ 表示女  $C_{1}$ 表示男，$x_{0}$ 表示驾龄，$x_{1}$ 表示平均车速。我们先来计算这个人为女性的概率相对值。根据统计数据，女性司机的概率 $P\left(C_{0}\right)=5 / 10=0.5$ ，。驾龄为2年的女性司机的概率即 $P\left(x_{0} \mid C_{0}\right)=1 / 5=0.2$ 。平均车速为80的女性司机的概率  $P\left(x_{1} \mid C_{0}\right)=1 / 5=0.2$，根据朴素贝叶斯分类算法的数学公式：</p>
<p>$$<br>P\left(C_{0}\right) \prod_{i=1}^{n} P\left(x_{i} \mid C_{0}\right)=0.5 \times 0.2 \times 0.2=0.02<br>$$<br>接着计算这个人为男性的概率相对值。根据统计数据，不难得出男性司机的概率 $P\left(C_{1}\right)=5 / 10=0.5$ 。驾龄为2年的男性司机的概率 $P\left(x_{0} \mid C_{1}\right)=2 / 5=0.4$ 。平均车速为80的男性司机的概率 $P\left(x_{1} \mid C_{1}\right)=3 / 5=0.6$<br>$$<br>P\left(C_{1}\right) \prod_{i=1}^{n} P\left(x_{i} \mid C_{1}\right)=0.5 \times 0.4 \times 0.6=0.12<br>$$<br>从相对概率来看，这个人是男性的概率是女性的概率的6倍，据此判断这个人是男性。我们也可以从相对概率中算出绝对概率，即这个人是男性的绝对概率是0.12/(0.12+0.02)=0.857。</p>
<h2 id="4-概率分布"><a href="#4-概率分布" class="headerlink" title="4.概率分布"></a>4.概率分布</h2><p>到目前为止，我们介绍的朴素贝叶斯分类算法是根据数据集里的数据，计算出绝对概率来进行求解。再看一遍朴素贝叶斯分类算法的数学公式：<br>$$<br>P\left(C_{k} \mid x\right) \propto P\left(C_{k}\right) \prod_{i=1}^{n} P\left(x_{i} \mid C_{k}\right)<br>$$<br>其中， $P\left(C_{k} \mid x\right) $表示在类别$C_{k}$ 里特征$x_{i}$ 出现的概率。这里有个最大的问题，如果数据集太小，那么从数据集里计算出来的概率偏差将非常严重。例如，观察一个质地均匀的骰子投掷6次的结果是[1,3,1,5,3,3]。质地均匀的骰子每个点出现的概率都是1/6，如果根据观察到的数据集去计算每个点的概率，和真实的概率相差将是非常大的。</p>
<p>怎么解决这个问题呢？答案是使用概率分布来计算概率，而不是从数据集里计算概率。</p>
<h3 id="4-1-概率统计的基本概念"><a href="#4-1-概率统计的基本概念" class="headerlink" title="4.1 概率统计的基本概念"></a>4.1 概率统计的基本概念</h3><p>人的身高是一个连续的随机变量，而投掷一个骰子得到的点数则是一个离散的随机变量。我们闭着眼睛随便找一个人，问这个人的身高是170cm的可能性是多大呢？如果有一个函数，能描述人类身高的可能性，那么直接把170cm代入即可求出这个可能性。这个函数就是概率密度函数，也称为<code>PDF（Probability Density Function）</code>。典型的概率密度函数是高斯分布函数，如人类的身高就满足高斯分布的规律。</p>
<p>再例如，投掷一个质地均匀的骰子，得到6的概率是多少呢？大家都知道答案是1/6。假如有一个函数f(x)，能描述骰子出现x点数的概率，那么把x代入即可得到概率，这个函数称为概率质量函数，即PMF（Probability Mass Function）。那么，为什么还有使用概率质量函数呢？一是在数学上追求统一性，二是并不是所有的离散随机变量的概率分布都像掷一次骰子这个直观。例如，投掷6次质地均匀的骰子，得到4个4的概率是多少？这个时候如果有概率质量函数，就可以轻松求解了。</p>
<blockquote>
<p>总结一下，随机变量分成两种，一种是连续随机变量，另外一种是离散随机变量。概率密度函数描述的是连续随机变量在某个特定值的可能性，概率质量函数描述的是离散随机变量在某个特定值的可能性。而概率分布则是描述随机变量取值的概率规律。</p>
</blockquote>
<h3 id="4-2-多项式分布"><a href="#4-2-多项式分布" class="headerlink" title="4.2 多项式分布"></a>4.2 多项式分布</h3><p> 抛一枚硬币，要么出现正面，要么出现反面（假设硬币不会立起来）。假如出现正面的概率是p，则出现反面的概率就是1-p。符合这个规律的概率分布，称为 <code>伯努利分布（Bernoulli Distribution）</code>。其概率质量函数为：<br>$$<br>f(k ; p)=p^{k}(1-p)^{1-k}<br>$$<br>p是出现1的概率。例如，一枚质地均匀的硬币被抛一次，得到正面的概率为0.5。我们代入上述公式，也可以得到相同的结果，即f(1;0.5)=0.5。</p>
<p>更一般的情况，即不止两种可能性时，假设每种可能性是$p_{i}$, 则满足  $\sum_{i}^{n} p_{i}=1$， 条件的概率分布，称为<code>类别分布（Categorical Distribution）</code>。例如，投掷一枚骰子，则会出现6中可能性，所有的可能性加起来的概率为1。类别分布的概率质量函数为：<br>$$<br>f(x \mid p)=\prod_{i=1}^{k} p_{i}^{x_{i}}<br>$$<br>那么，一枚质地均匀的硬币被抛10次，出现3次正面的概率是多少呢？这是个典型的二项式分布问题。二项式分布指的是把符号伯努利分布的实验做了n次，结果1出现0次、1次、2次……n次的概率分别是多少，它的概率质量函数为：<br>$$<br>f(k ; n, p)=C_{n}^{k} p^{k}(1-p)^{n-k}<br>$$<br>枚质地均匀的硬币被抛10次，出现3次正面的概率是多少？代入二项式分布的概率质量函数，得到：<br>$$<br>f(3 ; 10,0.5)=\frac{10 !}{3 ! \times(10-3) !} \times 0.5^{3} \times(1-0.5)^{10-3}=0.1171875<br>$$<br>其中，0的阶乘为1，即0!=1。结果跟我们预期的相符。当实验只做一次时，二项式分布退化为伯努利分布。</p>
<p>简单总结一下，二项式分布描述的是多次伯努利实验中，某个结果出现次数的概率。多项式分布描述的是多次进行满足类别分布的实验中，所有类别出现的次数组合的分布。</p>
<p>二项式分布和多项式分布结合朴素贝叶斯算法，经常被用来实现文章分类算法。例如，有一个论坛需要对用户的评论进行过滤，屏蔽不文明的评论。首先要有一个经过标记的数据集，我们称为语料库。假设使用人工标记的方法对评论进行标记，1表示不文明的评论，0表示正常评论。</p>
<p>假设我们的词库大小为 k ，则评论中出现某个词可以看成是一次满足k个类别的类别分布实验。我们知道，一篇评论是由n个词组成的，因此一篇评论可以看出是进行n次类别分布实验后的产物。由此得知，一篇评论服从多项式分布，它是词库里的所有词语出现的次数组合构成的随机向量。</p>
<p>一般情况下，词库比较大，评论只是由少量词组成，所以这个随机向量是很稀疏的，即大部分元素为0。通过分析预料库，我们容易统计出每个词出现在不文明评论及正常评论的概率，即 $p_{i}$的值。同时针对待预测的评论，我们可以统计词库里的所有词在这篇评论里出现的次数即  $x_{i}$ 的值，及评论的词语个数。代入多项式分布的概率质量函数：<br>$$<br>f(X, n, P)=\frac{n !}{\prod_{i=1}^{k} x_{i} !} \prod_{i=1}^{k} p_{i}^{x_{i}}<br>$$<br>我们可以求出，待预测评论构成的随机向量x，其为不文明评论的相对概率。同理也可以求出其为正常评论的相对概率。通过比较两个相对概率，就可以对这篇评论输出一个预测值。当然，实际应用中，涉及大量的自然语言处理的手段，包括中文分词技术、词的数学表示等，这里不再展开。</p>
<h3 id="4-3-高斯分布"><a href="#4-3-高斯分布" class="headerlink" title="4.3 高斯分布"></a>4.3 高斯分布</h3><p>在前面的车速和性别预测的例子里，对于平均车速，给出的是离散值，实际上它是一个连续值。这个时候怎么使用贝叶斯算法来处理呢？答案是，可以用区间把连续值转换成离散值。例如，我们可以把平均车速[0,40]作为一个级别，[40-80]，等等。这样就可以把连续值变成离散值，从而使用贝叶斯算法进行处理。另外一个方法，是使用连续随机变量的概率密度函数，把数值转换为一个相对概率。高斯分布就是这样一种方法。</p>
<p><code>高斯分布（Gaussian Distribution）</code>也称为 <code>正态分布（Normal Distribution）</code>，是最常见的一种分布。例如人的身高满足高斯分布，特别高和特别矮的人出现的相对概率都很低，大部分人身高都处在中间水平。还有人的智商也符合高斯分布，特别聪明的天才和特别笨的人出现的相对概率都很低，大部分人的智力都差不多。高斯分布的概率密度函数为：<br>$$<br>f(x)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)<br>$$<br>其中，$x$ 为随机变量的值，$f(x)$ 为随机变量的相对概率，$\mu$为样本的平均值，其决定了高斯分布曲线的位置，<img src="/medias/loading.gif" data-original="https://math.jianshu.com/math?formula=%5Csigma" alt="\sigma">为标准差，其决定了高斯分布的幅度，$\sigma$ 值越大，分布越分散，<img src="/medias/loading.gif" data-original="https://math.jianshu.com/math?formula=%5Csigma" alt="\sigma">$\sigma$值越小，分布越集中。典型的高斯分布如下图所示：</p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/17634123-e4f8952fc25052e3.png" alt="img"></p>
<p>这里需要注意的是：高斯分布的概率密度函数和支持向量机里的高斯核函数的区别。二者的核心数学模型是相同的，但是目的不同。</p>
<h3 id="4-4-连续值得处理"><a href="#4-4-连续值得处理" class="headerlink" title="4.4 连续值得处理"></a>4.4 连续值得处理</h3><p>假设，有一组身体特征的统计数据如下：</p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/17634123-ab2a72e2cf69b3f1.png" alt="img"></p>
<p>假设某人身高6英尺，体重130榜，脚掌8英寸，请问此人的性别是什么？</p>
<p>根据朴素贝叶斯公式：<br>$$<br>P\left(C_{k} \mid x\right) \propto P\left(C_{k}\right) \prod_{i=1}^{n} P\left(x_{i} \mid C_{k}\right)<br>$$<br>针对待预测的这个人的数据$x$ ，我们只需要分别求出男性和女性的相对概率<br>$$<br>P(\text {Gender}) \times P(\text {Height} \mid \text {Gender}) \times P(\text {Weight} \mid \text {Gender}) \times P(\text {Feet} \mid \text {Gender})<br>$$<br>然后取相对概率较高的性别为预测值即可。这里的困难在于，所有的特征都是连续变量，无法根据统计数据计算概率。当然，这里我们可以使用区间法，把连续变量变为离散变量，然后再计算概率。但由于数据量较小，这显然不是一个好办法。由于人类身高、体重、脚掌尺寸满足高斯分布，因此更好的办法是使用高斯分布的概率密度函数来求相对概率。</p>
<p>首先，针对男性和女性，分别求出特征的平均值和方差：</p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/17634123-4755f7b16509dc1d.png" alt="img"></p>
<p>接着利用高斯分布的概率密度函数，来求解男性身高为6英尺的相对概率：<br>$$<br>P(\text {Height}=6 \mid \text {Male})=\frac{1}{\sqrt{2 \pi \times 0.035033^{2}}} \exp \left(-\frac{(6-5.855)^{2}}{2 \times 0.035033^{2}}\right) \approx 1.5789<br>$$<br>这里的关键是把连续值（身高）作为输入，通过高斯分布的概率密度函数的处理，直接转换为相对概率。注意这里是相对概率，所以其值大于1并未违反概率论规则。</p>
<h2 id="5-示例：文档分类"><a href="#5-示例：文档分类" class="headerlink" title="5. 示例：文档分类"></a>5. 示例：文档分类</h2><p>在 <code>scikit-learn</code>里，朴素贝叶斯算法在 <code>sklearn.naive_bayes</code> 包里实现，包含本文介绍的几种典型的概率分布算法。其中 <code>GaussianNB</code> 实现了高斯分布的朴素贝叶斯算法，<code>MultinomialNB</code> 实现了多项式分布的朴素贝叶斯算法，<code>BernoulliNB</code>实现了伯努利分布的朴素贝叶斯算法。朴素贝叶斯算法在自然语言处理领域有着广泛的应用，这里我们使用 <code>MultinomialNB</code> 来实现文档的自动分类。</p>
<h3 id="5-1-获取数据集"><a href="#5-1-获取数据集" class="headerlink" title="5.1 获取数据集"></a>5.1 获取数据集</h3><p>这里使用的数据集来自 mlcomp.org上的20news-18828，可以直接访问<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=http%3A%2F%2Fmlcomp.org%2Fdatasets%2F379">http://mlcomp.org/datasets/379</a>下载。其目录下包含3个子目录和一个名为metadata的介绍文件，数据集也可在百度网盘下载。，已分享。</p>
<blockquote>
<p>链接：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1uQNkLWIN0niz8-p8BppRJg">https://pan.baidu.com/s/1uQNkLWIN0niz8-p8BppRJg</a><br>提取码：bvhe<br>复制这段内容后打开百度网盘手机App，操作更方便哦</p>
</blockquote>
<p>我们将使用 <code>train</code> 子目录下的文档进行模型训练，然后使用 <code>test</code> 子目录下的文档进行模型测试。<code>train</code> 子目录下包含 20 个子目录，每个子目录代表一种文档的类型，子目录下的所有文档都是属于目录名称所标识的文档类型。可以随意浏览数据集，以便对数据集有一个感性的认识。例如，datasets/mlcomp/379/train/rec.autos/6652-103421是一个讨论汽车主题的帖子：</p>
<pre class="line-numbers language-kotlin"><code class="language-kotlin">Hahahahahaha<span class="token punctuation">.</span> gasp pant Hm<span class="token punctuation">,</span> I’m not sure whether the above was just a silly 
    remark <span class="token operator">or</span> a serious remark<span class="token punctuation">.</span> But <span class="token keyword">in</span> case there are some misconceptions<span class="token punctuation">,</span>
I think Henry Robertson hasn’t updated his <span class="token keyword">data</span> file on Korea since…mid 1970s<span class="token punctuation">.</span> 
Owning a car <span class="token keyword">in</span> Korea <span class="token keyword">is</span> no longer a luxury<span class="token punctuation">.</span> Most middle <span class="token keyword">class</span> people 
<span class="token keyword">in</span> Korea can afford a car <span class="token operator">and</span> <span class="token keyword">do</span> have at least one car<span class="token punctuation">.</span> The problem <span class="token keyword">in</span> Korea<span class="token punctuation">,</span>
especially <span class="token keyword">in</span> Seoul<span class="token punctuation">,</span> <span class="token keyword">is</span> that there are just so many privately<span class="token operator">-</span>owned cars<span class="token punctuation">,</span>
<span class="token keyword">as</span> well <span class="token keyword">as</span> taxis <span class="token operator">and</span> buses<span class="token punctuation">,</span> the rush<span class="token operator">-</span>hour has become a <span class="token number">24</span> hour phenomenon 
    <span class="token operator">and</span> that there <span class="token keyword">is</span> no place <span class="token keyword">to</span> park<span class="token punctuation">.</span> Last time I heard<span class="token punctuation">,</span> back <span class="token keyword">in</span> January<span class="token punctuation">,</span> 
the Kim Administration wanted <span class="token keyword">to</span> legislate a law requireing a potential 
car owner <span class="token keyword">to</span> provide his <span class="token operator">or</span> her own parking area<span class="token punctuation">,</span> just like they <span class="token keyword">do</span> <span class="token keyword">in</span> Japan<span class="token punctuation">.</span>
Also<span class="token punctuation">,</span> Henry would be glad <span class="token keyword">to</span> know that Hyundai isn’t the only car manufacturer 
<span class="token keyword">in</span> Korea<span class="token punctuation">.</span> Daewoo has always manufactured cars <span class="token operator">and</span> I believe Kia <span class="token keyword">is</span> back <span class="token keyword">in</span> 
business <span class="token keyword">as</span> well<span class="token punctuation">.</span> Imported cars<span class="token punctuation">,</span> such <span class="token keyword">as</span> Mercury Sable are becoming quite 
popular <span class="token keyword">as</span> well<span class="token punctuation">,</span> though they are still quite expensive<span class="token punctuation">.</span>
Finally<span class="token punctuation">,</span> please ignore Henry’s posting about Korean politics <span class="token operator">and</span> bureaucracy<span class="token punctuation">.</span> 
    He’s quite uninformed<span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="5-2-文档的数学表达"><a href="#5-2-文档的数学表达" class="headerlink" title="5.2 文档的数学表达"></a>5.2 文档的数学表达</h3><p>怎样把一个文档表达为计算机可以理解并处理的信息，是自然语言处理中的一个重要课题，完整内容可以写成鸿篇巨著。本节简单介绍TF-IDF的原理，以便更好地理解本文介绍的实例。</p>
<p><code>TF-IDF</code> 是一种统计方法，用以评估一个词语对于一份文档的重要程度。<code>TF（Term Frequency）</code>表示词频，对于一份文档而言，词频是指特定词语在这篇文档里出现的次数除以该文档总词数。例如，一篇文档一共有1000个词，其中“朴素贝叶斯”出现了5次，“的”出现了25次，“应用”出现了12次，那么它们的词频分别是0.005，0.025和0.012。</p>
<p><code>IDF（Inverse Document Frequency）</code>表示一个词的逆向文档频率，由总文档数除以包含该词的文档数的商再取对数得到。例如：我们的数据集一共10000篇文档，其中“朴素贝叶斯”只出现在10篇文档中，则其<code>IDF=log(10000/10)=3</code>；“的”在所有文档中都出现过，则其 <code>IDF=log(10000/10000)=0</code>；“应用”在1000篇文档中出现过，则其 <code>IDF=log(10000/1000)=1</code>。</p>
<p>计算出每个词的TF和IDF之后，两者相乘，即可得到这个词在文档中的重要程度。词语的重要性与它在该文档中出现的次数成正比，与它在语料库中出现的文档数成反比。</p>
<p>有了TF-IDF这个工具，我们就可以把一篇文档转换为一个向量。首先，可以从数据集<code>（在自然语言处理领域也称corpus，即语料库）</code>里提取出所有出现的词，我们称为词典。假设词典里总共有10000个词语，则每个文档都可以转化为一个10000维的向量。其次，针对我们要转换的文档里出现的每个词语，都去计算其TF-IDF，并把这个值填入文档向量里这个词对应的元素上。这样就完成了把一篇文档转换为一个向量的过程。一个文档往往只会由词典里的一小部分词语构成，这就意味着这个向量里的大部分元素都是0。</p>
<p>所幸，上述过程不需要我们自己写代码去完成，<code>scikit-learn</code> 软件包里实现了把文档转换为向量的过程。首先，把训练用的语料库读入内存：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> time <span class="token keyword">import</span> time
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_files
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loading train dataset ..."</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> time<span class="token punctuation">(</span><span class="token punctuation">)</span>
news_train <span class="token operator">=</span> load_files<span class="token punctuation">(</span><span class="token string">'datasets/mlcomp/379/train'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"summary: {0} documents in {1} categories."</span>
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span>len<span class="token punctuation">(</span>news_train<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>news_train<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"done in {0} seconds"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-bash"><code class="language-bash">loading train dataset <span class="token punctuation">..</span>.
summary: 13180 documents <span class="token keyword">in</span> 20 categories.
<span class="token keyword">done</span> <span class="token keyword">in</span> 1.2616519927978516 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>其中，<code>datasets/mlcomp/379/train</code>目录下放的就是我们的语料库，其中包含20个子目录，每个子目录的名字表示的是文档的类别，子目录下包含这种类别的所有文档。<code>load_files()</code> 函数会从这个目录里把所有的文档都读入内存，并且自动根据所在的子目录名称打上标签。其中，<code>news_train.data</code>是一个数组，里面包含了所有文档的文本信息。<code>news_train.target</code>也是一个数组，包含了所有文档所属的类别，而<code>news_train.target_names</code>则是类别的名称，因此，如果我们想知道第一篇文档所属的类别名称，只需要通过代码<code>news_train.target_names[news_train.target[0]]</code>即可得到。</p>
<p>该语料库里总共有13180个文档，分成20个类别。接着需要把这些文档全部转换为由TF-IDF表达的权重信息构成的向量：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"vectorizing train dataset ..."</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> time<span class="token punctuation">(</span><span class="token punctuation">)</span>
vectorizer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>encoding<span class="token operator">=</span><span class="token string">'latin-1'</span><span class="token punctuation">)</span>
X_train <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span><span class="token punctuation">(</span>d <span class="token keyword">for</span> d <span class="token keyword">in</span> news_train<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"n_samples: %d, n_features: %d"</span> <span class="token operator">%</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"number of non-zero features in samples [{0}]:{1}"</span>
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span>news_train<span class="token punctuation">.</span>filenames<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>getnnz<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"done in {0} seconds"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-css"><code class="language-css">vectorizing train dataset <span class="token number">...</span>
<span class="token property">n_samples</span><span class="token punctuation">:</span> <span class="token number">13180</span>, <span class="token property">n_features</span><span class="token punctuation">:</span> <span class="token number">130274</span>
number of non-zero features in samples [datasets/mlcomp/<span class="token number">379</span>/train\talk<span class="token number">.</span>politics<span class="token number">.</span>misc<span class="token entity" title="\17860">\17860</span>-<span class="token number">178992</span>]<span class="token punctuation">:</span><span class="token number">108</span>
done in <span class="token number">2.6174726486206055</span> seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>其中，<code>TfidfVectorizer</code>类是用来把所有的文档转换为矩阵，该矩阵每行都代表一个文档，一行中的每个元素代表一个对应的词语的重要性，词语的重要性由<code>TF-IDF</code>来表示。其 <code>fit_transform()</code> 方法是 fit() 和transform()合并起来。其中，fit()  会先完成语料库分析、提取词典等操作，transform()会把对每篇文档转换为向量，最终构成一个矩阵，保存在X_train变量里。</p>
<p>由输出可以知道，我们的词典总共有 130274 个词语，即每篇文档都可转换为一个 130274 维的向量。第一篇文档中，只有108个非零元素，即这篇文档总共由108个不重复的单词组成，在这篇文档中出现的这108个单词的TF-IDF值会被计算出来，并保存在向量中的指定位置上。X_train是一个维度为13180*130274的稀疏矩阵。</p>
<p>X_train稀疏矩阵由一个三元组(row,col,score)构成：</p>
<pre class="line-numbers language-bash"><code class="language-bash">print<span class="token punctuation">(</span>X_train<span class="token punctuation">[</span>0<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-css"><code class="language-css">  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">56813</span><span class="token punctuation">)</span>    <span class="token number">0.014332663773643272</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">45689</span><span class="token punctuation">)</span>    <span class="token number">0.08373343949755</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">46084</span><span class="token punctuation">)</span>    <span class="token number">0.08109733529789522</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">125882</span><span class="token punctuation">)</span>   <span class="token number">0.0873157704840211</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">50150</span><span class="token punctuation">)</span>    <span class="token number">0.020654313721609956</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">87702</span><span class="token punctuation">)</span>    <span class="token number">0.04643235585055511</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">33334</span><span class="token punctuation">)</span>    <span class="token number">0.1025405658189532</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">111805</span><span class="token punctuation">)</span>   <span class="token number">0.</span><span class="token property">014332663773643272</span>
  <span class="token punctuation">:</span> <span class="token punctuation">:</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">67768</span><span class="token punctuation">)</span>    <span class="token number">0.08982314745972582</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">41790</span><span class="token punctuation">)</span>    <span class="token number">0.09260592033433869</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">105800</span><span class="token punctuation">)</span>   <span class="token number">0.08713990737243116</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">37075</span><span class="token punctuation">)</span>    <span class="token number">0.10018566542781165</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">23162</span><span class="token punctuation">)</span>    <span class="token number">0.08920437523600384</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">124699</span><span class="token punctuation">)</span>   <span class="token number">0.06257976758779137</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">94119</span><span class="token punctuation">)</span>    <span class="token number">0.1159317059788844</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">56555</span><span class="token punctuation">)</span>    <span class="token number">0.06984885482106491</span>
  <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">62776</span><span class="token punctuation">)</span>    <span class="token number">0.10474995568339582</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="5-3-模型训练"><a href="#5-3-模型训练" class="headerlink" title="5.3 模型训练"></a>5.3 模型训练</h3><p>使用 <code>MultinomialNB</code> 对数据集进行训练：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>naive_bayes <span class="token keyword">import</span> MultinomialNB
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"training models ..."</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> time<span class="token punctuation">(</span><span class="token punctuation">)</span>
y_train <span class="token operator">=</span> news_train<span class="token punctuation">.</span>target
clf <span class="token operator">=</span> MultinomialNB<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
train_score <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train score: {0}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>train_score<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"done in {0} seconds"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-css"><code class="language-css">training models <span class="token number">...</span>
train <span class="token property">score</span><span class="token punctuation">:</span> <span class="token number">0.9978755690440061</span>
done in <span class="token number">0.15497064590454102</span> seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>其中，alpha表示平滑参数，其值越小，越容易造成过拟合，值太大，容易造成欠拟合。</p>
<p>接着，我们加载测试数据集，并用一篇文档来预测其是否准确。测试数据集在<code>datasets/mlcomp/379/test</code>目录下，我们用前面介绍的相同的方法先加载数据集：</p>
<pre class="line-numbers language-go"><code class="language-go"><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"loading test dataset ..."</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> <span class="token function">time</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
news_test <span class="token operator">=</span> <span class="token function">load_files</span><span class="token punctuation">(</span><span class="token string">'datasets/mlcomp/379/test'</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"summary: {0} documents in {1} categories."</span>
      <span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>news_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token function">len</span><span class="token punctuation">(</span>news_test<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"done in {0} seconds"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token function">time</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-bash"><code class="language-bash">loading <span class="token function">test</span> dataset <span class="token punctuation">..</span>.
summary: 5648 documents <span class="token keyword">in</span> 20 categories.
<span class="token keyword">done</span> <span class="token keyword">in</span> 0.3548290729522705 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>测试数据集共有5648篇文档。接着，我们把文档向量化：</p>
<pre class="line-numbers language-bash"><code class="language-bash">print<span class="token punctuation">(</span><span class="token string">"vectorizing test dataset ..."</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> time<span class="token punctuation">(</span><span class="token punctuation">)</span>
X_test <span class="token operator">=</span> vectorizer.transform<span class="token variable"><span class="token punctuation">((</span>d for d in news_test.data<span class="token punctuation">))</span></span>
y_test <span class="token operator">=</span> news_test.target
print<span class="token punctuation">(</span><span class="token string">"n_samples: %d, n_features: %d"</span> % X_test.shape<span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">"number of non-zero features in sample [{0}]: {1}"</span>
      .format<span class="token punctuation">(</span>news_test.filenames<span class="token punctuation">[</span>0<span class="token punctuation">]</span>,X_test<span class="token punctuation">[</span>0<span class="token punctuation">]</span>.getnnz<span class="token punctuation">(</span><span class="token punctuation">))</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">"done in {0} seconds"</span>.format<span class="token punctuation">(</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>-t<span class="token punctuation">))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-bash"><code class="language-bash">vectorizing <span class="token function">test</span> dataset <span class="token punctuation">..</span>.
n_samples: 5648, n_features: 130274
number of non-zero features <span class="token keyword">in</span> sample <span class="token punctuation">[</span>datasets/mlcomp/379/test\rec.autos\7429-103268<span class="token punctuation">]</span>: 61
<span class="token keyword">done</span> <span class="token keyword">in</span> 0.9695498943328857 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意，vectorizer变量是我们处理训练数据集时用到的向量化的类的实例，此处我们只需要调用transform()进行TF-IDF数值计算即可，不需要再调用fit()进行语料库分析了。</p>
<p>这样，我们的测试数据集也转换为了一个维度为5648*130274的稀疏矩阵。可以取测试数据集里的第一篇文档初步验证一下，看看训练出来的模型能否正确地预测这个文档所属的类别：</p>
<pre class="line-numbers language-bash"><code class="language-bash">pred <span class="token operator">=</span> clf.predict<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span>0<span class="token punctuation">]</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">"predict: {0} is in category {1}"</span>
      .format<span class="token punctuation">(</span>news_test.filenames<span class="token punctuation">[</span>0<span class="token punctuation">]</span>,news_test.target_names<span class="token punctuation">[</span>pred<span class="token punctuation">[</span>0<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">))</span>
print<span class="token punctuation">(</span><span class="token string">"actually: {0} is in category {1}"</span>
      .format<span class="token punctuation">(</span>news_test.filenames<span class="token punctuation">[</span>0<span class="token punctuation">]</span>,news_test.target_names<span class="token punctuation">[</span>news_test.target<span class="token punctuation">[</span>0<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-bash"><code class="language-bash">predict: datasets/mlcomp/379/test\rec.autos\7429-103268 is <span class="token keyword">in</span> category rec.autos
actually: datasets/mlcomp/379/test\rec.autos\7429-103268 is <span class="token keyword">in</span> category rec.autos<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>看来预测的结果和实际结果是相符的。</p>
<h3 id="5-4-模型评价"><a href="#5-4-模型评价" class="headerlink" title="5.4 模型评价"></a>5.4 模型评价</h3><p>虽然通过验证，说明我们训练的模型是可用的，但是不能通过一个样本的预测来评价模型的准确性。我们需要对模型有个全方位的评价，所幸 <code>scikit-learn</code> 软件包提供了全方位的模型评价工具。</p>
<p>首先需要对测试数据集进行预测：</p>
<pre class="line-numbers language-bash"><code class="language-bash">print<span class="token punctuation">(</span><span class="token string">"predicting test dataset ..."</span><span class="token punctuation">)</span>
t <span class="token operator">=</span> time<span class="token punctuation">(</span><span class="token punctuation">)</span>
pred_test <span class="token operator">=</span> clf.predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">"done in %fs"</span> % <span class="token punctuation">(</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>-t<span class="token punctuation">))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>接着使用 <code>classification_report()</code> 函数来查看一下针对每个类别的预测准确性：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> classification_report
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"classification report on test set for classifier:"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>clf<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>pred_test<span class="token punctuation">,</span>target_names<span class="token operator">=</span>news_test<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-bash"><code class="language-bash">classification report on <span class="token function">test</span> <span class="token keyword">set</span> <span class="token keyword">for</span> classifier:
MultinomialNB<span class="token punctuation">(</span>alpha<span class="token operator">=</span>0.0001, class_prior<span class="token operator">=</span>None, fit_prior<span class="token operator">=</span>True<span class="token punctuation">)</span>
                          precision    recall  f1-score   support

             alt.atheism       0.90      0.91      0.91       245
           comp.graphics       0.80      0.90      0.85       298
 comp.os.ms-windows.misc       0.82      0.79      0.80       292
comp.sys.ibm.pc.hardware       0.81      0.80      0.81       301
   comp.sys.mac.hardware       0.90      0.91      0.91       256
          comp.windows.x       0.88      0.88      0.88       297
            misc.forsale       0.87      0.81      0.84       290
               rec.autos       0.92      0.93      0.92       324
         rec.motorcycles       0.96      0.96      0.96       294
      rec.sport.baseball       0.97      0.94      0.96       315
        rec.sport.hockey       0.96      0.99      0.98       302
               sci.crypt       0.95      0.96      0.95       297
         sci.electronics       0.91      0.85      0.88       313
                 sci.med       0.96      0.96      0.96       277
               sci.space       0.94      0.97      0.96       305
  soc.religion.christian       0.93      0.96      0.94       293
      talk.politics.guns       0.91      0.96      0.93       246
   talk.politics.mideast       0.96      0.98      0.97       296
      talk.politics.misc       0.90      0.90      0.90       236
      talk.religion.misc       0.89      0.78      0.83       171

             avg / total       0.91      0.91      0.91      5648<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从输出结果中可以看出，针对每种类别都统计了<code>查准率</code>、<code>召回率</code>和<code>F1-Score</code>。此外，还可以通过confusion_matrix()函数生成混淆矩阵，观察每种类别被错误分类的情况。例如，这些被错误分类的文档是被错误分类到哪些类别里的：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix
cm <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>pred_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"confusion matrix:\n"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出如下：</p>
<pre class="line-numbers language-csharp"><code class="language-csharp">confusion matrix<span class="token punctuation">:</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">224</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">5</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">1</span>  <span class="token number">13</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span> <span class="token number">267</span>   <span class="token number">5</span>   <span class="token number">5</span>   <span class="token number">2</span>   <span class="token number">8</span>   <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">3</span>   <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">0</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span>  <span class="token number">13</span> <span class="token number">230</span>  <span class="token number">24</span>   <span class="token number">4</span>  <span class="token number">10</span>   <span class="token number">5</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">1</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">9</span>  <span class="token number">21</span> <span class="token number">242</span>   <span class="token number">7</span>   <span class="token number">2</span>  <span class="token number">10</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">7</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">0</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">5</span>   <span class="token number">5</span> <span class="token number">233</span>   <span class="token number">2</span>   <span class="token number">2</span>   <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">3</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">0</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>  <span class="token number">20</span>   <span class="token number">6</span>   <span class="token number">3</span>   <span class="token number">1</span> <span class="token number">260</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">0</span>    <span class="token number">0</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">5</span>  <span class="token number">12</span>   <span class="token number">3</span>   <span class="token number">1</span> <span class="token number">235</span>  <span class="token number">10</span>   <span class="token number">2</span>   <span class="token number">3</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">7</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">1</span>    <span class="token number">4</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">8</span> <span class="token number">300</span>   <span class="token number">4</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">2</span>   <span class="token number">3</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">0</span>    <span class="token number">1</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">2</span>   <span class="token number">3</span> <span class="token number">283</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">1</span>   <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">2</span>   <span class="token number">0</span> <span class="token number">297</span>   <span class="token number">8</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">0</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">2</span> <span class="token number">298</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">0</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">2</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span> <span class="token number">284</span>   <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">1</span>    <span class="token number">2</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>  <span class="token number">11</span>   <span class="token number">3</span>   <span class="token number">5</span>   <span class="token number">4</span>   <span class="token number">2</span>   <span class="token number">4</span>   <span class="token number">5</span>   <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">4</span> <span class="token number">266</span>   <span class="token number">1</span>   <span class="token number">4</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>    <span class="token number">1</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span> <span class="token number">266</span>   <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>    <span class="token number">1</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span>   <span class="token number">3</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">1</span> <span class="token number">296</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>    <span class="token number">1</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">3</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">1</span> <span class="token number">280</span>   <span class="token number">0</span>   <span class="token number">1</span>    <span class="token number">1</span>   <span class="token number">2</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">2</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span> <span class="token number">236</span>   <span class="token number">1</span>    <span class="token number">4</span>   <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">3</span>   <span class="token number">0</span> <span class="token number">290</span>    <span class="token number">1</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">2</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">1</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">1</span>  <span class="token number">10</span>   <span class="token number">7</span>  <span class="token number">212</span>   <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">16</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span>  <span class="token number">12</span>   <span class="token number">4</span>   <span class="token number">1</span>    <span class="token number">4</span> <span class="token number">134</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>例如：从第一行可以看出，类别0（alt.atheism）的文档，有13个被错误地分类到类别19（talk.religion.misc）里。当然，我们还可以把混淆矩阵进行数据可视化：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Show confusion matrix</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dpi<span class="token operator">=</span><span class="token number">144</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Confusion matrix of the classifier'</span><span class="token punctuation">)</span>
ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'right'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'top'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'bottom'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>spines<span class="token punctuation">[</span><span class="token string">'left'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_ticks_position<span class="token punctuation">(</span><span class="token string">'none'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_yticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>cm<span class="token punctuation">,</span>fignum<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出图形如下：</p>
<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/dongzhougu/imageuse1/image-20200702160731221.png" alt="image-20200702160731221">除对角线外，其他地方颜色越浅，说明此处错误越多。通过这些数据，我们可以详细分析样本数据，找出为什么某种类别会被错误地分类到另一种类别里，从而进一步优化模型。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">DongZhou</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://dongzhougu.github.io/2020/07/02/scikit-learn-xi-lie-qi-po-su-bei-xie-si/">https://dongzhougu.github.io/2020/07/02/scikit-learn-xi-lie-qi-po-su-bei-xie-si/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://dongzhougu.github.io" target="_blank">欢迎来到，TWOTO 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/07/15/scikit-learn-xi-lie-ba-pca/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">scikit-learn系列八：PCA</div></div></a></div><div class="next-post pull-right"><a href="/2020/07/01/scikit-learn-xi-lie-liu-svm/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">scikit-learn系列六：SVM</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/07/16/ji-qi-xue-xi-suan-fa-shi-xian/" title="机器学习算法实现"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-16</div><div class="title">机器学习算法实现</div></div></a></div><div><a href="/2020/06/28/scikit-learn-xi-lie-yi-ji-qi-xue-xi-ji-chu/" title="scikit-learn系列一：机器学习基础"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-28</div><div class="title">scikit-learn系列一：机器学习基础</div></div></a></div><div><a href="/2020/07/16/scikit-learn-xi-lie-jiu-k-jun-zhi/" title="scikit-learn系列九：K-均值"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-16</div><div class="title">scikit-learn系列九：K-均值</div></div></a></div><div><a href="/2020/06/30/scikit-learn-xi-lie-san-xian-xing-hui-gui/" title="scikit-learn系列三：线性回归"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-30</div><div class="title">scikit-learn系列三：线性回归</div></div></a></div><div><a href="/2020/06/30/scikit-learn-xi-lie-wu-jue-ce-shu/" title="scikit-learn系列五：决策树"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-30</div><div class="title">scikit-learn系列五：决策树</div></div></a></div><div><a href="/2020/06/29/scikit-learn-xi-lie-er-k-jin-lin/" title="scikit-learn系列二：K-近邻"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-29</div><div class="title">scikit-learn系列二：K-近邻</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">DongZhou</div><div class="author-info__description">技术、效率、摄影</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">29</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%E4%BC%A0%E9%80%81%E9%97%A8%EF%BC%8C%E6%AC%A2%E8%BF%8E-star-%E5%92%8C-fork-%EF%BC%81"><span class="toc-number">1.</span> <span class="toc-text">项目地址传送门，欢迎 star 和 fork ！</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A6%82%E8%BF%B0"><span class="toc-number">2.</span> <span class="toc-text">1. 朴素贝叶斯概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA-amp-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">3.</span> <span class="toc-text">2. 贝叶斯理论 &amp; 条件概率</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%AE%BA"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 贝叶斯理论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 条件概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E4%BD%BF%E7%94%A8%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E6%9D%A5%E5%88%86%E7%B1%BB"><span class="toc-number">3.3.</span> <span class="toc-text">2.3 使用条件概率来分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="toc-number">4.</span> <span class="toc-text">3. 一个简单的例子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="toc-number">5.</span> <span class="toc-text">4.概率分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 概率统计的基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%88%86%E5%B8%83"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 多项式分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="toc-number">5.3.</span> <span class="toc-text">4.3 高斯分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E8%BF%9E%E7%BB%AD%E5%80%BC%E5%BE%97%E5%A4%84%E7%90%86"><span class="toc-number">5.4.</span> <span class="toc-text">4.4 连续值得处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%A4%BA%E4%BE%8B%EF%BC%9A%E6%96%87%E6%A1%A3%E5%88%86%E7%B1%BB"><span class="toc-number">6.</span> <span class="toc-text">5. 示例：文档分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">6.1.</span> <span class="toc-text">5.1 获取数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%96%87%E6%A1%A3%E7%9A%84%E6%95%B0%E5%AD%A6%E8%A1%A8%E8%BE%BE"><span class="toc-number">6.2.</span> <span class="toc-text">5.2 文档的数学表达</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">6.3.</span> <span class="toc-text">5.3 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7"><span class="toc-number">6.4.</span> <span class="toc-text">5.4 模型评价</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/15/yuque/springboot-zheng-he-redis/" title="SpringBoot-整合Redis">SpringBoot-整合Redis</a><time datetime="2021-11-15T11:11:53.000Z" title="发表于 2021-11-15 19:11:53">2021-11-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/15/yuque/fen-bu-shi-xiao-xi-zhong-jian-jian-gai-shu/" title="分布式消息中间件-概述">分布式消息中间件-概述</a><time datetime="2021-11-15T10:58:22.000Z" title="发表于 2021-11-15 18:58:22">2021-11-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/15/yuque/springboot-qian-hou-duan-fen-chi-kua-yu-pei-zhi/" title="SpringBoot-前后端分离跨域配置">SpringBoot-前后端分离跨域配置</a><time datetime="2021-11-15T06:57:12.000Z" title="发表于 2021-11-15 14:57:12">2021-11-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/14/yuque/mybatis-jia-gou-yu-yuan-li/" title="MyBatis-架构与原理">MyBatis-架构与原理</a><time datetime="2021-11-14T04:59:00.000Z" title="发表于 2021-11-14 12:59:00">2021-11-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/14/yuque/mybatis-huan-cun-gong-zuo-yuan-li/" title="Mybatis-缓存工作原理">Mybatis-缓存工作原理</a><time datetime="2021-11-14T04:58:08.000Z" title="发表于 2021-11-14 12:58:08">2021-11-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By DongZhou</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var i=n.imageLazyLoadSetting.isSPA,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){i&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,e,a=0;a<r.length;a++)t=r[a],e=void 0,0<=(e=t.getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(n.innerHeight||document.documentElement.clientHeight)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},n.src=i}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body></html>